{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing required dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:08.701285Z",
     "iopub.status.busy": "2025-04-16T06:20:08.701074Z",
     "iopub.status.idle": "2025-04-16T06:20:17.530170Z",
     "shell.execute_reply": "2025-04-16T06:20:17.529558Z",
     "shell.execute_reply.started": "2025-04-16T06:20:08.701261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "import psutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.532355Z",
     "iopub.status.busy": "2025-04-16T06:20:17.531633Z",
     "iopub.status.idle": "2025-04-16T06:20:17.538739Z",
     "shell.execute_reply": "2025-04-16T06:20:17.538070Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.532332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    model_name: str = \"bert-base-uncased\"\n",
    "    num_labels: int = 4\n",
    "    max_length: int = 128\n",
    "    train_batch_size: int = 64\n",
    "    eval_batch_size: int = 32\n",
    "    learning_rate: float = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    num_epochs: int = 4\n",
    "    warmup_steps: int = 500\n",
    "    gradient_accumulation_steps: int = 2\n",
    "    train_size: float = 0.8\n",
    "    random_seed: int = 42\n",
    "    num_workers: int = 4\n",
    "    data_dir: str = \"data\"\n",
    "    model_dir: str = \"models\"\n",
    "    output_dir: str = \"outputs\"\n",
    "    patience: int = 3\n",
    "    min_delta: float = 1e-4\n",
    "    device: Optional[str] = None\n",
    "    log_interval: int = 100\n",
    "    eval_interval: int = 500\n",
    "    fp16: bool = False\n",
    "    max_grad_norm: float = 1.0\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.539830Z",
     "iopub.status.busy": "2025-04-16T06:20:17.539548Z",
     "iopub.status.idle": "2025-04-16T06:20:17.565658Z",
     "shell.execute_reply": "2025-04-16T06:20:17.564918Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.539804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    return text.strip().replace(\"\\\\n\", \" \").replace(\"\\\\\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.566552Z",
     "iopub.status.busy": "2025-04-16T06:20:17.566322Z",
     "iopub.status.idle": "2025-04-16T06:20:17.575639Z",
     "shell.execute_reply": "2025-04-16T06:20:17.575019Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.566533Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AGNewsDataset(Dataset):\n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int):\n",
    "        self.texts = [clean_text(t) for t in texts]\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def load_and_process_data(config) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    dataset = load_dataset(\"ag_news\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    train_val = dataset[\"train\"].train_test_split(test_size=0.2, seed=config.random_seed)\n",
    "    test = dataset[\"test\"]\n",
    "\n",
    "    train_set = AGNewsDataset(train_val[\"train\"][\"text\"], train_val[\"train\"][\"label\"], tokenizer, config.max_length)\n",
    "    val_set = AGNewsDataset(train_val[\"test\"][\"text\"], train_val[\"test\"][\"label\"], tokenizer, config.max_length)\n",
    "    test_set = AGNewsDataset(test[\"text\"], test[\"label\"], tokenizer, config.max_length)\n",
    "\n",
    "    return (\n",
    "        DataLoader(train_set, batch_size=config.train_batch_size, shuffle=True),\n",
    "        DataLoader(val_set, batch_size=config.eval_batch_size),\n",
    "        DataLoader(test_set, batch_size=config.eval_batch_size)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.576679Z",
     "iopub.status.busy": "2025-04-16T06:20:17.576384Z",
     "iopub.status.idle": "2025-04-16T06:20:17.591595Z",
     "shell.execute_reply": "2025-04-16T06:20:17.591027Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.576664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, model_name: str, num_labels: int):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "    def save_pretrained(self, path):\n",
    "        self.bert.save_pretrained(path)\n",
    "        torch.save(self.classifier.state_dict(), f\"{path}/classifier.pt\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, path, num_labels):\n",
    "        model = cls(path, num_labels)\n",
    "        model.classifier.load_state_dict(torch.load(f\"{path}/classifier.pt\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.592807Z",
     "iopub.status.busy": "2025-04-16T06:20:17.592491Z",
     "iopub.status.idle": "2025-04-16T06:20:17.608291Z",
     "shell.execute_reply": "2025-04-16T06:20:17.607616Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.592774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(config, model_name):\n",
    "    wandb.init(project=\"ag-news-bert-finetune\", config=config.__dict__)\n",
    "    config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.manual_seed(config.random_seed)\n",
    "    np.random.seed(config.random_seed)\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_and_process_data(config)\n",
    "    model = BERTClassifier(model_name, config.num_labels).to(config.device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "    total_steps = len(train_loader) * config.num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, config.warmup_steps, total_steps)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_test_loss = float('inf')  \n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(config.num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss, train_steps = 0, 0\n",
    "        for step, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}\")):\n",
    "            batch = {k: v.to(config.device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs['loss'] / config.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % config.gradient_accumulation_steps == 0:\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_train_loss += loss.item() * config.gradient_accumulation_steps\n",
    "            train_steps += 1\n",
    "\n",
    "            if step % config.log_interval == 0:\n",
    "                wandb.log({\n",
    "                    \"train_loss\": loss.item(),\n",
    "                    \"learning_rate\": scheduler.get_last_lr()[0],\n",
    "                    \"memory_usage_mb\": get_memory_usage()['rss']\n",
    "                })\n",
    "\n",
    "            if step % config.eval_interval == 0:\n",
    "                test_loss, test_metrics = evaluate(model, test_loader, config)\n",
    "                wandb.log({\n",
    "                    \"test_loss\": test_loss,\n",
    "                    \"test_accuracy\": test_metrics['accuracy'],\n",
    "                    \"test_f1\": test_metrics['f1']\n",
    "                })\n",
    "                if test_loss < best_test_loss:\n",
    "                    best_test_loss = test_loss\n",
    "                    os.makedirs(config.model_dir, exist_ok=True)\n",
    "                    model.save_pretrained(f\"{config.model_dir}/best_model\")\n",
    "\n",
    "        avg_train_loss = total_train_loss / train_steps\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        val_loss, val_metrics = evaluate(model, val_loader, config)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss_epoch\": avg_train_loss, \"val_loss\": val_loss, **val_metrics})\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            os.makedirs(config.model_dir, exist_ok=True)\n",
    "            model.save_pretrained(f\"{config.model_dir}/best_model\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config.patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    return model, train_losses, val_losses, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.610375Z",
     "iopub.status.busy": "2025-04-16T06:20:17.610135Z",
     "iopub.status.idle": "2025-04-16T06:20:17.623757Z",
     "shell.execute_reply": "2025-04-16T06:20:17.622909Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.610361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(preds, labels):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average='weighted'),\n",
    "        \"confusion_matrix\": confusion_matrix(labels, preds)\n",
    "    }\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return {'rss': process.memory_info().rss // (1024 * 1024)}\n",
    "    \n",
    "def evaluate(model, dataloader, config):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(config.device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            total_loss += outputs['loss'].item()\n",
    "            preds = torch.argmax(outputs['logits'], dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    metrics = compute_metrics(all_preds, all_labels)\n",
    "    return avg_loss, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.624458Z",
     "iopub.status.busy": "2025-04-16T06:20:17.624301Z",
     "iopub.status.idle": "2025-04-16T06:20:17.661452Z",
     "shell.execute_reply": "2025-04-16T06:20:17.660740Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.624444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def final_evaluation(config):\n",
    "    model = BERTClassifier.from_pretrained(f\"{config.model_dir}/best_model\", config.num_labels).to(config.device)\n",
    "    _, _, test_loader = load_and_process_data(config)\n",
    "    test_loss, test_metrics = evaluate(model, test_loader, config)\n",
    "\n",
    "    print(\"Test Loss:\", test_loss)\n",
    "    print(\"Test Accuracy:\", test_metrics['accuracy'])\n",
    "    print(\"Test F1:\", test_metrics['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:17.662734Z",
     "iopub.status.busy": "2025-04-16T06:20:17.662396Z",
     "iopub.status.idle": "2025-04-16T06:20:23.348382Z",
     "shell.execute_reply": "2025-04-16T06:20:23.347852Z",
     "shell.execute_reply.started": "2025-04-16T06:20:17.662688Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtavdevinit44\u001b[0m (\u001b[33mtavdevinit44-thinkbiz-technology-pvt\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"ab2237bc8b2d7af0b2465cbd0eb84a45a2ebc941\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T06:20:23.349427Z",
     "iopub.status.busy": "2025-04-16T06:20:23.348996Z",
     "iopub.status.idle": "2025-04-16T08:49:42.299372Z",
     "shell.execute_reply": "2025-04-16T08:49:42.298447Z",
     "shell.execute_reply.started": "2025-04-16T06:20:23.349409Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_062023-mj0o0k4l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tavdevinit44-thinkbiz-technology-pvt/ag-news-bert-finetune/runs/mj0o0k4l' target=\"_blank\">eager-field-8</a></strong> to <a href='https://wandb.ai/tavdevinit44-thinkbiz-technology-pvt/ag-news-bert-finetune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tavdevinit44-thinkbiz-technology-pvt/ag-news-bert-finetune' target=\"_blank\">https://wandb.ai/tavdevinit44-thinkbiz-technology-pvt/ag-news-bert-finetune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tavdevinit44-thinkbiz-technology-pvt/ag-news-bert-finetune/runs/mj0o0k4l' target=\"_blank\">https://wandb.ai/tavdevinit44-thinkbiz-technology-pvt/ag-news-bert-finetune/runs/mj0o0k4l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d3e110291f4150a7ac3c0523a7b0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e9a0ae54d4418aba0fc112dcaf0939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6320695c8af74115af28d4716a83b647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60451a877dc4e56a448c3799ff00397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d893713ff346baaadd81a2814d6194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4befc69ad584cb08c32b9eb06844e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204393f346054ce895194b4a9ef4cda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5348bf2d38476cbcb30ff6d7612c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d14bbf97854fbcac412008dacd37b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 06:20:43.554807: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744784443.741557      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744784443.799098      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d388d95aa9e54168960d7ecea0d7494e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1500/1500 [34:18<00:00,  1.37s/it]  \n",
      "Epoch 2: 100%|██████████| 1500/1500 [34:26<00:00,  1.38s/it]  \n",
      "Epoch 3: 100%|██████████| 1500/1500 [34:25<00:00,  1.38s/it]  \n",
      "Epoch 4: 100%|██████████| 1500/1500 [34:23<00:00,  1.38s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trained_model, train_losses, val_losses, test_loader = train(config,model_name=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Distilbert for comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# trained_model1, train_losses1, val_losses1, test_loader1 = train(config,model_name=\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final evaluation output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T08:49:42.301987Z",
     "iopub.status.busy": "2025-04-16T08:49:42.301160Z",
     "iopub.status.idle": "2025-04-16T08:50:40.197555Z",
     "shell.execute_reply": "2025-04-16T08:50:40.196854Z",
     "shell.execute_reply.started": "2025-04-16T08:49:42.301966Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31/416449541.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.classifier.load_state_dict(torch.load(f\"{path}/classifier.pt\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.16443919879579996\n",
      "Test Accuracy: 0.9426315789473684\n",
      "Test F1: 0.9426630045475902\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "final_evaluation(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
